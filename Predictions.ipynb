{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee1af801",
   "metadata": {},
   "source": [
    "# Model predictions\n",
    "+ Speech-to-Text\n",
    "+ GUI implementation\n",
    "+ Audio file conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a39523cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import keras\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa.display\n",
    "import simpleaudio as sa\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53828df",
   "metadata": {},
   "source": [
    "## Load in models, encoders and other objects needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7edcb221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "loaded_clf = joblib.load(\"Models/TextModel.joblib\")\n",
    "loaded_keras = keras.models.load_model('Models/AudioModel')\n",
    "dkeras = keras.models.load_model('Models/AudioModel')\n",
    "gkeras = keras.models.load_model('Models/GenderedAudioModel')\n",
    "\n",
    "# Load vectorizer for text model\n",
    "file_to_read = open(\"Objects/vectorizer.obj\", \"rb\")\n",
    "vect = pickle.load(file_to_read)\n",
    "\n",
    "# Load OneHotEncoder for audio signal model\n",
    "file_to_read2 = open(\"Objects/encoder.obj\", \"rb\")\n",
    "enc = pickle.load(file_to_read2)\n",
    "denc = enc\n",
    "\n",
    "file_to_read3 = open(\"Objects/encoderGendered.obj\", \"rb\")\n",
    "genderenc = pickle.load(file_to_read3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44639970",
   "metadata": {},
   "source": [
    "### Go through the list of files and convert them all to .wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9466e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_wav():\n",
    "    import os\n",
    "    directory = \"./TestAudio/\"\n",
    "    for filename in os.listdir(directory):\n",
    "        filetype = filename.split(\".\")[1]\n",
    "        fullfile = directory + filename\n",
    "        if filetype != \"wav\":\n",
    "            try:\n",
    "                output = (directory + filename.split(\".\")[0] + \".wav\")\n",
    "                audSeg = AudioSegment.from_file(fullfile)\n",
    "                audSeg.export(output, format=\"wav\")\n",
    "                os.remove(fullfile)\n",
    "            except:\n",
    "                {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e100576",
   "metadata": {},
   "source": [
    "### Define functions for both models predictor logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c819debf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_signal(filename, loaded_keras, enc):\n",
    "    #Extract MFCC's\n",
    "    y, sr = librosa.load(filename, duration=6, offset=0.5)\n",
    "    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n",
    "    feature = pd.DataFrame(data=mfcc)\n",
    "    feature = feature.stack().to_frame().T\n",
    "    twodim = np.expand_dims(feature, axis=2)\n",
    "    pred = loaded_keras.predict(twodim, batch_size=32, verbose=1)\n",
    "    \n",
    "    #Predict using keras audio model\n",
    "    prediction = (enc.inverse_transform(pred))\n",
    "    return prediction[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43fa05d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(filename):\n",
    "    r = sr.Recognizer()\n",
    "    #Audio to Text\n",
    "    with sr.AudioFile(filename) as source:\n",
    "        # listen for the data (load audio to memory)\n",
    "        audio_data = r.record(source)\n",
    "        # recognize (convert from speech to text)\n",
    "        text = r.recognize_google(audio_data)\n",
    "\n",
    "    #Predict using random forest model\n",
    "    testfeat = vect.transform([text])\n",
    "    prediction = loaded_clf.predict(testfeat)\n",
    "    return prediction[0], text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93769994",
   "metadata": {},
   "source": [
    "## Other functions needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0d99ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSoundDuration(path):\n",
    "    sound = AudioSegment.from_file(path)\n",
    "    sound.duration_seconds == (len(sound) / 1000.0)\n",
    "    minutes_duration = int(sound.duration_seconds // 60)\n",
    "    seconds_duration = round((sound.duration_seconds % 60))\n",
    "    return minutes_duration, seconds_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "430a8bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_model(boolean):\n",
    "    if (boolean==True):\n",
    "        return gkeras, genderenc\n",
    "    else:\n",
    "        return dkeras, denc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3696c39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "\n",
    "def waveplot(path):\n",
    "    data, sr = librosa.load(path)\n",
    "    plt.title(\"Sound Wave\")\n",
    "    plt.ylabel('dB')\n",
    "    librosa.display.waveplot(data, sr)\n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4151feaa",
   "metadata": {},
   "source": [
    "### GUI (PySimpleGUI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471636dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n"
     ]
    }
   ],
   "source": [
    "import PySimpleGUI as sg\n",
    "import os.path\n",
    "\n",
    "boolean = True\n",
    "abspath = os.path.abspath(\"./TestAudio/\")\n",
    "currentFile = \"\"\n",
    "play_obj = None\n",
    "\n",
    "def get_list():\n",
    "    full_list = os.listdir(abspath)\n",
    "    wav_list = []\n",
    "    for f in full_list:\n",
    "        if f.split(\".\")[1] == \"wav\":\n",
    "            mins, secs = getSoundDuration(abspath+\"//\"+f)\n",
    "            if mins==0 and secs < 12 and secs > 1:\n",
    "                wav_list.append(f)\n",
    "    return wav_list\n",
    "\n",
    "def draw_figure(canvas, figure):\n",
    "    figure_canvas_agg = FigureCanvasTkAgg(figure, canvas)\n",
    "    figure_canvas_agg.draw()\n",
    "    figure_canvas_agg.get_tk_widget().pack(side='top', fill='both', expand=1)\n",
    "    plt.close()\n",
    "    return figure_canvas_agg\n",
    "\n",
    "def delete_figure(figure_canvas_agg):\n",
    "    figure_canvas_agg.get_tk_widget().forget()\n",
    "    plt.close('all')\n",
    "\n",
    "refresh_tooltip = \"After adding or removing a file from the path, click here to refresh the list.\\n\\u2022 If the file added is an M4A, MP4 or other compatible audio file, it will also be converted to .wav first \\n\\u2022 If the file is not compatible and/or can't be converted, it won't be displayed in the list\\n \\u2022 Compatible audio files must be between 1 and 13 seconds in duration\"\n",
    "\n",
    "left_column = [\n",
    "    [\n",
    "        sg.Text(\"Speech file path: \"),\n",
    "        sg.Text(abspath),\n",
    "        sg.Button(\"Go to the path\", key=\"PathButton\", tooltip=\"Add or remove audio files to process\"),\n",
    "        sg.Button(\"Refresh\", key=\"Refresh\", tooltip=refresh_tooltip)\n",
    "    ],\n",
    "    [\n",
    "        sg.Listbox(\n",
    "        values=get_list(), enable_events=True, size=(40,20), key=\"FileList\"\n",
    "        )\n",
    "    ],\n",
    "    [\n",
    "        sg.Button(\"Switch model to gendered model\", key=\"Switch\", tooltip=\"Model will change the next time a file is chosen for processing\"),\n",
    "    ]\n",
    "]\n",
    "\n",
    "mid_column = [\n",
    "    [sg.Text(\"Choose a file from the list\")],\n",
    "    [sg.Button(\"Play\"), sg.Button(\"Stop\")],\n",
    "    [sg.Text(\"Words in the audio file: \")],\n",
    "    [sg.Text(key=\"SpeechText\")],\n",
    "    [sg.Text(\"Prediction based on audio signals:\")],\n",
    "    [sg.Text(key=\"AudioPred\")],\n",
    "    [sg.Text(\"Prediction based on words spoken:\")],\n",
    "    [sg.Text(key=\"WordsPred\")],\n",
    "    [sg.Text(key=\"gap\")],\n",
    "    [sg.Text(key=\"Error\")],\n",
    "    [sg.Text(key=\"Error2\")],\n",
    "]\n",
    "\n",
    "right_column = [\n",
    "    [sg.Text(\"Select an audio file to display the graph...\", key=\"GraphText\")],\n",
    "    [sg.Canvas(key='Canvas')],\n",
    "]\n",
    "\n",
    "layout = [\n",
    "    [\n",
    "        sg.Column(left_column),\n",
    "        sg.VSeparator(),\n",
    "        sg.Column(mid_column),\n",
    "        sg.Column(right_column),\n",
    "    ]\n",
    "]\n",
    "\n",
    "window = sg.Window(title=\"Speech emotion predictor\", layout=layout, margins=(100,100), finalize=True,\n",
    "                   icon=\"icon.ico\")\n",
    "\n",
    "figure_canvas_agg = None\n",
    "\n",
    "while True:\n",
    "    event, values = window.read()\n",
    "    \n",
    "    if event == \"PathButton\":\n",
    "        os.startfile(abspath)\n",
    "    \n",
    "    if event == \"Refresh\":\n",
    "        convert_to_wav()\n",
    "        window[\"FileList\"].update(get_list())\n",
    "    \n",
    "    if event == \"Switch\":\n",
    "        loaded_keras, enc = switch_model(boolean)\n",
    "        if (boolean):\n",
    "            boolean = False\n",
    "            window[\"Switch\"].update(\"Switch model to default model\")\n",
    "        else: \n",
    "            boolean = True\n",
    "            window[\"Switch\"].update(\"Switch model to gendered model\")\n",
    "            \n",
    "    if event == \"Play\":\n",
    "        try:\n",
    "            if play_obj != None:\n",
    "                play_obj.stop()\n",
    "            wave_obj = sa.WaveObject.from_wave_file(filename)\n",
    "            play_obj = wave_obj.play()\n",
    "        except Exception as e:\n",
    "            window[\"Error\"].update(\"Error with playback:\", text_color=\"red\", font=\"bold\", visible=True)\n",
    "            window[\"Error2\"].update(str(e), text_color=\"red\", font=\"bold\", visible=True)\n",
    "        \n",
    "    if event == \"Stop\":\n",
    "        try:\n",
    "            play_obj.stop()\n",
    "        except:\n",
    "            {}\n",
    "    \n",
    "    \n",
    "    if event == \"FileList\":\n",
    "        try:\n",
    "            window[\"Error\"].update(visible=False)\n",
    "            window[\"Error2\"].update(visible=False)\n",
    "            pred_signal_out = \"\"\n",
    "            currentFile = filename = os.path.join(abspath, values[\"FileList\"][0])\n",
    "            pred_signal_out = predict_signal(filename, loaded_keras, enc)\n",
    "            pred_text_out, text_to_predict = predict_text(filename)\n",
    "                      \n",
    "            window[\"SpeechText\"].update(text_to_predict, text_color=\"pink\")\n",
    "            window[\"AudioPred\"].update(pred_signal_out, text_color=\"pink\")\n",
    "            window[\"WordsPred\"].update(pred_text_out, text_color=\"pink\")\n",
    "            \n",
    "            if figure_canvas_agg:\n",
    "                delete_figure(figure_canvas_agg)\n",
    "            \n",
    "            fig = waveplot(filename)\n",
    "            figure_canvas_agg = draw_figure(window['Canvas'].TKCanvas, fig)\n",
    "            window[\"GraphText\"].update(\"Graph of \" + filename.split(\"\\\\\")[-1])     \n",
    "        except:\n",
    "            error = \"Error with this file\"\n",
    "            if figure_canvas_agg:\n",
    "                delete_figure(figure_canvas_agg)\n",
    "            figure_canvas_agg = draw_figure(window['Canvas'].TKCanvas, None)\n",
    "            window[\"SpeechText\"].update(error, text_color=\"pink\")\n",
    "            window[\"AudioPred\"].update(error, text_color=\"pink\")\n",
    "            window[\"WordsPred\"].update(error, text_color=\"pink\")\n",
    "            window[\"GraphText\"].update(\"Error with \" + filename.split(\"\\\\\")[-1])     \n",
    "\n",
    "    if event == sg.WIN_CLOSED:\n",
    "        break\n",
    "window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d2d3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
